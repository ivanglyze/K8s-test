# K8s-test
# A Helm chart for a web app

# Вводные тестовой задачи:
1. У нас мультизональный кластер (три зоны), в котором пять нод
2. Приложение требует около 5-10 секунд для инициализации
3. По результатам нагрузочного теста известно, что 4 пода справляются с пиковой нагрузкой
4. На первые запросы приложению требуется значительно больше ресурсов CPU, в дальнейшем потребление ровное в районе 0.1 CPU. По памяти всегда “ровно” в районе 128M memory
5. Приложение имеет дневной цикл по нагрузке – ночью запросов на порядки меньше, пик – днём
6. Хотим максимально отказоустойчивый deployment
7. Хотим минимального потребления ресурсов от этого deployment’а

# Принятые решения:
Во-первых, стоит сказать, что для разработки деплоймента веб-приложения для удобства и комфорта при работе, а также легкой поддерживаемости кода, выбор пал на Helm Chart.
1. Был выбран механизм antiAffinity для обеспечения отказоустойчивости и "расселения" подов по разным зонам, чтобы не было риска падения всего веб-приложения, если минимальное количество реплик (2) находилось бы в ставшими нефункциональными одной и той же зоне и/или ноде.  
2. Для временной задержки при инициализации приложения был использован readinessProbe, который будет проверять готовность контейнера принимать трафик через 12 секунд с момента запуска контейнера. Также для обеспечения дальнейшей отказоустойчивости был использован livenessProbe, чтобы проверять контейнеры на зависания и перезапускать их при таковых. Исполнение проб будет осуществляться через tcpSocket, так как httpGet и exec могут быть более ресурсоемкими, что идет против минимального потребления ресурсов в пункте 7, так что просто запрос через tcpSocket оптимален, по моему мнению.
3. Балансировка трафика будет производиться при помощи сервиса loadBalancer, ingress в качестве балансировщика для одного деплоймента не выглядит необходимым.
4. При масштабировании, минимальные и максимальные значения количества реплик назначены на 2 и 4 соответственно. Хотелось поставить больше, чем 4 и поставить выше контрольное значение утилизации ресурсов, чтобы при непредвиденных нагрузках запускались дополнительные реплики, но раз результаты нагрузочного теста показывают, что 4 пода справляются с пиковой нагрузкой, то в маловероятном случае таких нагрузок, реплики можно заскейлить вручную. Также, дневные и ночные циклы нагрузки натолкнули на мысль выполнения действий по расписанию, используя cronJobs, например, но HPA в данной ситуации должен справиться с задачей. 
5. Для первых запросов, требующих значительно больше ресурсов, значение лимита на CPU было выставлено на уровне 0.4m. Не уверен, насколько значительно больше требуют первые запросы, но 0.5m точно звучит как слишком много, есть ощущение, что можно снизить до 0.3m или даже 0.25m. По памяти и запросы и лимиты были выставлены на уровне 128Mi. Масштабирование будет выполнять по контрольным значениям 85% утилизации ресурсов.
6. Также, пока изучал лимиты часто натыкался на мнение о том, что ставить limits на CPU в целом не является лучшей практикой из-за того, как работают механизмы троттлинга в k8s, так что теоретически, исходя из литературы, которую изучал, CPU limits можно вообще убрать, но пока что опыта не хватает, чтобы оценить как это повлияет на работу приложения в конкретно данной ситуации. В любом случае, было написано, что не ожидается production-ready решение, в реальной ситуации можно было бы протестировать работу приложения с лимитом и без, чтобы посмотреть внесло бы это какие-то изменения или нет.   
